model:
  name: FacebookAI/xlm-roberta-large
  num_labels: 6
  classifier_dropout: 0.0
  hidden_dropout_prob: 0.0
  output_hidden_states: false

tokenizer:
    pretrained_model_name_or_path: ${model.name}
    truncation: true
    padding: true
    max_length: 512
    special_tokens: null

data: 
  train_file_path: data/lorem_ipsum.jsonl
  train_annotation_path: null
  train_file_split: train
  test_file_path: data/lorem_ipsum.jsonl # currently not used
  test_file_split: train # currently not used
  val_file_path: data/lorem_ipsum.jsonl
  val_annotation_path: null
  val_file_split: train
  gt_file_path: null # ground truth data; can be null (optional)
  gt_file_split: train
  label_column: scores
  text_column: text
  num_regressor_outputs: 1
  num_classes_per_output: [6]
  output_names: ["score"]
  annotator_average_fn: median
  
training:
  batch_size: 32
  epochs: 10
  use_bf16: true
  weight_decay: 0.01
  eval_strategy: epoch
  save_strategy: epoch
  logging_steps: 100
  seed: 42
  regression_loss: false
  greater_is_better: false # save model with lowest loss
  metric_for_best_model: eval_val_loss
  learning_rate: 0.00001
  logging_dir_path: data/output/lorem_ipsum_model
  output_dir_path: data/output/lorem_ipsum_model