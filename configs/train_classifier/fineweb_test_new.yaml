model:
  name: FacebookAI/xlm-roberta-base
  num_labels: 6
  classifier_dropout: 0.0
  hidden_dropout_prob: 0.0
  output_hidden_states: false

tokenizer:
    pretrained_model_name_or_path: ${model.name}
    truncation: true
    padding: true
    max_length: 512
    special_tokens: null

data: 
  train_file_path: /raid/s3/opengptx/eurolingua/cc_debug_datasets/cc_debug_subset_100_docs_raw
  train_annotation_path: /raid/s3/opengptx/eurolingua/cc_debug_datasets/cc_debug_subset_100_docs_annotations
  train_file_split: train
  test_file_path: /raid/s3/opengptx/eurolingua/cc_debug_datasets/cc_debug_subset_100_docs_raw # currently not used
  test_file_split: train # currently not used
  val_file_path: /raid/s3/opengptx/eurolingua/cc_debug_datasets/cc_debug_subset_100_docs_raw
  val_annotation_path: /raid/s3/opengptx/eurolingua/cc_debug_datasets/cc_debug_subset_100_docs_annotations
  val_file_split: train
  gt_file_path: null # ground truth data; can be null (optional)
  gt_file_split: train
  label_column: scores
  text_column: text
  num_regressor_outputs: 2
  num_classes_per_output: [6, 6]
  output_names: ["score", "score2"]
  annotator_average_fn: median
  
training:
  batch_size: 32
  epochs: 10
  use_bf16: true
  weight_decay: 0.01
  eval_strategy: epoch
  save_strategy: epoch
  logging_steps: 100
  seed: 42
  regression_loss: false
  greater_is_better: false # save model with lowest loss
  metric_for_best_model: eval_val_loss
  learning_rate: 0.00001
  logging_dir_path: data/output/lorem_ipsum_model
  output_dir_path: data/output/lorem_ipsum_model