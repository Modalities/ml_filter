model:
  name: Snowflake/snowflake-arctic-embed-m-v2.0 # check model
  freeze_base_model_parameters: true  # Add option to freeze encoder
  num_tasks: ${data.num_tasks}  # Number of prediction tasks
  num_targets_per_task: ${data.num_targets_per_task}  # Number of classes per output
  is_regression: ${training.is_regression}
  normalize_embeddings: true  # Normalize embeddings to unit length

tokenizer:
  pretrained_model_name_or_path: ${model.name}
  truncation: true
  padding: longest
  max_length: 8192 # Snowflake embed v2.0 uses 8192 tokens as max length
  add_generation_prompt: true

data:
  dataset_type: pth  # jsonl or pth
  train_file_path: /raid/s3/opengptx/jude/repos/ml_filter/hessanAI/hessan_ai_data/train_dataset_bf16.pth # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/temp_train # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/final_dataset/training_set # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/data_training/training_set  # /home/alex-jude/training_set
#  train_file_path: /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/temp_train/train1.jsonl # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/final_dataset/training_set # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/data_training/training_set  # /home/alex-jude/training_set
  train_file_split: train
  test_file_path:
#  test_file_path: /raid/s3/opengptx/jude/repos/ml_filter/hessanAI/hessan_ai_data/Mistral-Small-3.1-24B-Instruct-2503_aggregated/embedding_score_gt_revamp.pth
  test_file_split: train
#  val_file_path: /raid/s3/opengptx/jude/repos/ml_filter/hessanAI/hessan_ai_data/train_dataset_bf16_uniform.pth # /raid/s3/opengptx/jude/repos/ml_filter/hessanAI/hessan_ai_data/Mistral-Small-3.1-24B-Instruct-2503_aggregated/embedding_score_gt_revamp.pth # /raid/s3/opengptx/jude/repos/ml_filter/hessanAI/hessan_ai_data/val_dataset_bf16_uniform.pth # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/temp_train # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/final_dataset/validation_set # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/data_training/validation_set  # /home/alex-jude/validation_set
  val_file_path: /raid/s3/opengptx/jude/repos/ml_filter/hessanAI/hessan_ai_data/Mistral-Small-3.1-24B-Instruct-2503_aggregated/embedding_score_gt_revamp.pth # /raid/s3/opengptx/jude/repos/ml_filter/hessanAI/hessan_ai_data/val_dataset_bf16_uniform.pth # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/temp_train # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/final_dataset/validation_set # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/data_training/validation_set  # /home/alex-jude/validation_set
#  val_file_path: /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/temp_train/train1.jsonl # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/final_dataset/validation_set # /raid/s3/opengptx/jude/repos/ml_filter/data/sampled_data/data_training/validation_set  # /home/alex-jude/validation_set
  val_file_split: train
  label_column: scores  # Ensure this matches dataset format
  text_column: text  # Ensure this matches dataset format
  document_id_column: id  # Ensure this matches dataset format
  num_tasks: 1
  num_targets_per_task: [6]
  task_names: ["edu"]
  num_processes: 64
  save_embeddings: true  # Set to true if you want to save embeddings
  embedding_file_path: /raid/s3/opengptx/jude/repos/ml_filter/data


training:
  batch_size: 4
  eval_batch_size: 4 # 1024
  epochs: 20
  use_bf16: true
  weight_decay: 0.01 # 0.01
  eval_strategy: steps
  save_strategy: "no"
  logging_steps: 10
  seed: 42
  is_regression: true
  greater_is_better: false  # Save model with lowest loss
  metric_for_best_model: eval_edu/spearman_corr
  learning_rate: 5e-04 # 5e-04
  logging_dir_path: data/output/fineweb_edu_model_artic_v2-m-finalll
  output_dir_path: ${training.logging_dir_path}
  dataloader_num_workers: 16
  load_best_model_at_end: false

wandb:
  experiment_name: HessanAI_Replication # name of the wandb project